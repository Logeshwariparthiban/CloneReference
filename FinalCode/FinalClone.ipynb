{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3381e9a2-883f-42e3-869b-31f43f2d612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from speechbrain.inference import Tacotron2, HIFIGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f4e3e02-6660-4a7a-ae42-0c1e5b0fc6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import librosa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8006ec69-4cbf-4877-85ba-9dfaab3b8926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8e622e3-e2aa-497e-89ae-7f04a0a9bd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d28f580-fcb0-4230-919e-817850abfdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tacotron2 = Tacotron2.from_hparams(source=\"speechbrain/tts-tacotron2-ljspeech\", \n",
    "                                   savedir=\"tmpdir_tts\")\n",
    "hifi_gan = HIFIGAN.from_hparams(source=\"speechbrain/tts-hifigan-ljspeech\", \n",
    "                                savedir=\"tmpdir_vocoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6b6217f-6199-40fc-93cc-18a2a32fe61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features from reference audio (your input voice)\n",
    "def extract_speaker_features(input_audio_path):\n",
    "    # Load the audio file (assumed to be in .wav format)\n",
    "    waveform, sample_rate = torchaudio.load(input_audio_path)\n",
    "    print(f\"Extracting features from: {input_audio_path}\")\n",
    "    return waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c465a5c-7494-454b-9b3e-944c5f5d67f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert input text to speech in the same voice style (using the input reference voice)\n",
    "def text_to_speech(input_text, input_audio_path, output_audio_path):\n",
    "    # Extract speaker features from the reference voice\n",
    "    reference_waveform = extract_speaker_features(input_audio_path)\n",
    "    \n",
    "    # Synthesize speech (text-to-mel spectrogram) from input text\n",
    "    mel_output, mel_length, alignment = tacotron2.encode_text(input_text)\n",
    "    \n",
    "    # Now, we need to modify the TTS output to match the reference voice characteristics\n",
    "    # For simplicity, we use the same vocoder (HIFIGAN) to decode the spectrogram\n",
    "    waveforms = hifi_gan.decode_batch(mel_output)  # Generate speech from mel spectrogram\n",
    "    \n",
    "    # Save the generated speech to the output file\n",
    "    torchaudio.save(output_audio_path, waveforms.squeeze(1), 22050)  # Save waveform\n",
    "    print(f\"Audio saved to {output_audio_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1217968e-9a07-462c-8b27-f0e6f6a6a73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example input parameters\n",
    "input_audio_file = \"voiceinput.wav\"  # Your input reference audio file (your voice)\n",
    "input_text = \"Hello, this is the text I want to be read out loud in my voice.\"\n",
    "output_audio_file = \"output.wav\"  # Path to save the output generated audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ed3a4bd-9798-4b84-95d6-eea27c2984f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from: voiceinput.wav\n",
      "Audio saved to output.wav\n"
     ]
    }
   ],
   "source": [
    "# Call the function to synthesize speech in the reference voice\n",
    "text_to_speech(input_text, input_audio_file, output_audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c1c8cf-c9f6-4f68-bc15-0ba6e1736c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102b2774-994a-4726-924a-3bbaad77dcbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33930649-8cca-462d-a2fd-ac568cf7b4c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (speech_clone)",
   "language": "python",
   "name": "speech_clone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
